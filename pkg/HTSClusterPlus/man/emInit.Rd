% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/emInit.R
\name{emInit}
\alias{emInit}
\title{Parameter initialization for a Poisson mixture model.}
\usage{
emInit(y, K, conds, norm, alg.type = "EM", init.runs, init.iter, fixed.lambda,
  equal.proportions, verbose)
}
\arguments{
\item{y}{(\emph{n} x \emph{q}) matrix of observed counts for \emph{n}
observations and \emph{q} variables}

\item{K}{Number of clusters (a single value). If \code{fixed.lambda}
contains a list of lambda values to be fixed, \code{K} corresponds to the
number of clusters in addition to those fixed.}

\item{conds}{Vector of length \emph{q} defining the condition (treatment
group) for each variable (column) in \code{y}}

\item{norm}{The type of estimator to be used to normalize for differences in
library size: (\dQuote{\code{TC}} for total count, \dQuote{\code{UQ}} for
upper quantile, \dQuote{\code{Med}} for median, \dQuote{\code{DESeq}} for
the normalization method in the DESeq package, and \dQuote{\code{TMM}} for
the TMM normalization method (Robinson and Oshlack, 2010). Can also be a
vector (of length \emph{q}) containing pre-estimated library size estimates
for each sample. Note that if the user provides pre-calculated normalization
factors, the package will make use of \code{norm/sum(norm)} as normalization
factors.}

\item{alg.type}{Algorithm to be used for parameter estimation
(\dQuote{\code{EM}} or \dQuote{\code{CEM}})}

\item{init.runs}{Number of runs to be used for the Small-EM strategy
described in Rau et al. (2011), with a default value of 1}

\item{init.iter}{Number of iterations to be used within each run for the
Small-EM strategry, with a default value of 10}

\item{fixed.lambda}{If one (or more) clusters with fixed values of lambda is
desired, a list containing vectors of length \emph{d} (the number of
conditions).  specifying the fixed values of lambda for each fixed cluster.}

\item{equal.proportions}{If \code{TRUE}, the cluster proportions are set to
be equal for all clusters. Default is \code{FALSE} (unequal cluster
proportions).}

\item{verbose}{If \code{TRUE}, include verbose output}
}
\value{
\item{pi.init }{Vector of length \code{K} containing the estimate
for \eqn{\hat{\ensuremath\boldsymbol{\pi}}}{\hat{\pi}} corresponding to the
highest log likelihood (or completed log likelihood) from the chosen
inialization strategy. }

\item{lambda.init }{(\emph{d} x \code{K}) matrix containing the estimate of
\eqn{\hat{\ensuremath\boldsymbol{\lambda}}}{\hat{\lambda}} corresponding to
the highest log likelihood (or completed log likelihood) from the chosen
initialization strategy, where \emph{d} is the number of conditions and
\code{K} is the number of clusters. }
}
\description{
This function implements the Small EM initialization strategy
(\code{emInit}) described in Rau et al. (2011).
}
\details{
In practice, the user will not directly call the initialization functions
described here; they are indirectly called for a single number of clusters
through the \code{PoisMixClus_K} function (via \code{init.type}) or via the
\code{PoisMixClus} function for a sequence of cluster numbers (via
\code{Kmin.init} and \code{split.init}).

To initialize parameter values for the EM and CEM algorithms, for the
Small-EM strategy (Biernacki et al., 2003) we use the \code{emInit} function
as follows. For a given number of independent runs (given by
\code{init.runs}), the following procedure is used to obtain parameter
values: first, a K-means algorithm (MacQueen, 1967) is run to partition the
data into \code{g} clusters
(\eqn{\hat{\ensuremath\boldsymbol{z}}^{(0)}}{\hat{z}^(0)}). Second, initial
parameter values \eqn{\ensuremath\boldsymbol{\pi}^{(0)}}{\pi^(0)} and
\eqn{\ensuremath\boldsymbol{\lambda}^{(0)}}{\lambda^(0)} are calculated (see
Rau et al. (2011) for details). Third, a given number of iterations of an EM
algorithm are run (defined by \code{init.iter}), using
\eqn{\ensuremath\boldsymbol{\pi}^{(0)}}{\pi^(0)} and
\eqn{\ensuremath\boldsymbol{\lambda}^{(0)}}{\lambda^(0)} as initial values.
Finally, among the \code{init.runs} sets of parameter values, we use
\eqn{\hat{\ensuremath\boldsymbol{\lambda}}}{\hat{\lambda}} and
\eqn{\hat{\ensuremath\boldsymbol{\pi}}}{\hat{\pi}} corresponding to the
highest log likelihood or completed log likelihood to initialize the
subsequent full EM or CEM algorithms, respectively.
}
\author{
Andrea Rau <\url{andrea.rau@jouy.inra.fr}>
}
\references{
Anders, S. and Huber, W. (2010) Differential expression analysis
for sequence count data. \emph{Genome Biology}, \bold{11}(R106), 1-28.

Biernacki, C., Celeux, G., Govaert, G. (2003) Choosing starting values for
the EM algorithm for getting the highest likelhiood in multivariate Gaussian
mixture models. \emph{Computational Statistics and Data Analysis},
\bold{41}(1), 561-575.

MacQueen, J. B. (1967) Some methods for classification and analysis of
multivariate observations. In \emph{Proceedings of the 5th Berkeley
Symposium on Mathematical Statistics and Probability}, number 1, pages
281-297. Berkeley, University of California Press.

Papastamoulis, P., Martin-Magniette, M.-L., and Maugis-Rabusseau, C. (2014).
On the estimation of mixtures of Poisson regression models with large number
of components. \emph{Computational Statistics and Data Analysis}: 3rd
special Issue on Advances in Mixture Models, DOI:
10.1016/j.csda.2014.07.005.

Rau, A., Celeux, G., Martin-Magniette, M.-L., Maugis-Rabusseau, C. (2011).
Clustering high-throughput sequencing data with Poisson mixture models.
Inria Research Report 7786. Available at
\url{http://hal.inria.fr/inria-00638082}.

Rau, A., Maugis-Rabusseau, C., Martin-Magniette, M.-L., Celeux, G. (2015)
Co-expression analysis of high-throughput transcriptome sequencing data with
Poisson mixture models. Bioinformatics, doi: 10.1093/bioinformatics/btu845.

Robinson, M. D. and Oshlack, A. (2010) A scaling normalization method for
differential expression analysis of RNA-seq data. \emph{Genome Biology},
\bold{11}(R25).
}
\seealso{
\code{\link{PoisMixClus_K}} for Poisson mixture model estimation for
a given number of clusters, \code{\link{PoisMixClus}} for Poisson
mixture model estimation and model selection for a sequence of cluster
numbers.
}
\keyword{models}

